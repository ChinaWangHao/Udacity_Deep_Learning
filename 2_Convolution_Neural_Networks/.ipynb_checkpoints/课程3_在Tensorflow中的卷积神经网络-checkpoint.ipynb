{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 在Tensorflow中的卷积神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. TensorFlow 卷积层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output depth\n",
    "k_output = 64\n",
    "\n",
    "# Image Properties\n",
    "image_width = 10\n",
    "image_height = 10\n",
    "color_channels = 3\n",
    "\n",
    "# Convolution filter\n",
    "filter_size_width = 5\n",
    "filter_size_height = 5\n",
    "\n",
    "# Input/Image\n",
    "input = tf.placeholder(\n",
    "    tf.float32,\n",
    "    shape=[None, image_height, image_width, color_channels])\n",
    "\n",
    "# Weight and bias\n",
    "weight = tf.Variable(tf.truncated_normal(\n",
    "    [filter_size_height, filter_size_width, color_channels, k_output]))\n",
    "bias = tf.Variable(tf.zeros(k_output))\n",
    "\n",
    "# Apply Convolution\n",
    "conv_layer = tf.nn.conv2d(input, weight, strides=[1, 2, 2, 1], padding='SAME')\n",
    "# Add bias\n",
    "conv_layer = tf.nn.bias_add(conv_layer, bias)\n",
    "# Apply activation function\n",
    "conv_layer = tf.nn.relu(conv_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. TensorFlow 最大池化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Max Pooling\n",
    "conv_layer = tf.nn.max_pool(\n",
    "    conv_layer,\n",
    "    ksize=[1, 2, 2, 1],\n",
    "    strides=[1, 2, 2, 1],\n",
    "    padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. TensorFlow 中的卷积网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./train-images-idx3-ubyte.gz\n",
      "Extracting ./train-labels-idx1-ubyte.gz\n",
      "Extracting ./t10k-images-idx3-ubyte.gz\n",
      "Extracting ./t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\".\", one_hot=True, reshape=False)\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# Parameters\n",
    "# 参数\n",
    "learning_rate = 0.00001\n",
    "epochs = 2\n",
    "batch_size = 128\n",
    "\n",
    "# Number of samples to calculate validation and accuracy\n",
    "# Decrease this if you're running out of memory to calculate accuracy\n",
    "# 用来验证和计算准确率的样本数\n",
    "# 如果内存不够，可以调小这个数字\n",
    "test_valid_size = 256\n",
    "\n",
    "# Network Parameters\n",
    "# 神经网络参数\n",
    "n_classes = 10  # MNIST total classes (0-9 digits)\n",
    "dropout = 0.75  # Dropout, probability to keep units"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weights and Biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'wc1': tf.Variable(tf.random_normal([5, 5, 1, 32])),\n",
    "    'wc2': tf.Variable(tf.random_normal([5, 5, 32, 64])),\n",
    "    'wd1': tf.Variable(tf.random_normal([7*7*64, 1024])),\n",
    "    'out': tf.Variable(tf.random_normal([1024, n_classes]))}\n",
    "\n",
    "biases = {\n",
    "    'bc1': tf.Variable(tf.random_normal([32])),\n",
    "    'bc2': tf.Variable(tf.random_normal([64])),\n",
    "    'bd1': tf.Variable(tf.random_normal([1024])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, W, b, strides=1):\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了更简洁，这里的代码用了tf.nn.bias_add() 来添加偏置。 tf.add() 这里不能使用，因为 tensors 的维度不同。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maxpool2d(x, k=2):\n",
    "    return tf.nn.max_pool(x, \n",
    "                          ksize=[1, k, k, 1], \n",
    "                          strides=[1, k, k, 1], \n",
    "                          padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_net(x, weights, biases, dropout):\n",
    "    # Layer-1: 28 * 28 * 1 --> 14 * 14 * 32\n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
    "    conv1 = maxpool2d(conv1, k=2)\n",
    "    \n",
    "    # Layer-2: 14 * 14 * 32 --> 7 * 7 * 64\n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
    "    conv2 = maxpool2d(conv2, k=2)\n",
    "    \n",
    "    # Fully connected layer: 7 * 7 * 64 --> 1024\n",
    "    fc1 = tf.reshape(conv2, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    fc1 = tf.nn.dropout(fc1, dropout)\n",
    "    \n",
    "    # Output Layer - class prediction - 1024 to 10\n",
    "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1, Batch   1 -Loss: 58918.0469 Validation Accuracy: 0.058594\n",
      "Epoch  1, Batch   2 -Loss: 44450.5312 Validation Accuracy: 0.058594\n",
      "Epoch  1, Batch   3 -Loss: 38834.3086 Validation Accuracy: 0.078125\n",
      "Epoch  1, Batch   4 -Loss: 31864.6406 Validation Accuracy: 0.093750\n",
      "Epoch  1, Batch   5 -Loss: 33443.2773 Validation Accuracy: 0.117188\n",
      "Epoch  1, Batch   6 -Loss: 31975.8242 Validation Accuracy: 0.121094\n",
      "Epoch  1, Batch   7 -Loss: 24325.2539 Validation Accuracy: 0.121094\n",
      "Epoch  1, Batch   8 -Loss: 24768.7383 Validation Accuracy: 0.156250\n",
      "Epoch  1, Batch   9 -Loss: 23591.4824 Validation Accuracy: 0.152344\n",
      "Epoch  1, Batch  10 -Loss: 24910.8281 Validation Accuracy: 0.164062\n",
      "Epoch  1, Batch  11 -Loss: 21080.5527 Validation Accuracy: 0.187500\n",
      "Epoch  1, Batch  12 -Loss: 20479.2344 Validation Accuracy: 0.195312\n",
      "Epoch  1, Batch  13 -Loss: 20746.5234 Validation Accuracy: 0.191406\n",
      "Epoch  1, Batch  14 -Loss: 17508.0547 Validation Accuracy: 0.199219\n",
      "Epoch  1, Batch  15 -Loss: 16401.8184 Validation Accuracy: 0.203125\n",
      "Epoch  1, Batch  16 -Loss: 18118.9336 Validation Accuracy: 0.203125\n",
      "Epoch  1, Batch  17 -Loss: 16630.0566 Validation Accuracy: 0.218750\n",
      "Epoch  1, Batch  18 -Loss: 14682.3369 Validation Accuracy: 0.203125\n",
      "Epoch  1, Batch  19 -Loss: 16214.8184 Validation Accuracy: 0.210938\n",
      "Epoch  1, Batch  20 -Loss: 13436.0625 Validation Accuracy: 0.214844\n",
      "Epoch  1, Batch  21 -Loss: 14777.4893 Validation Accuracy: 0.238281\n",
      "Epoch  1, Batch  22 -Loss: 15342.0586 Validation Accuracy: 0.253906\n",
      "Epoch  1, Batch  23 -Loss: 12069.6875 Validation Accuracy: 0.242188\n",
      "Epoch  1, Batch  24 -Loss: 14137.1914 Validation Accuracy: 0.257812\n",
      "Epoch  1, Batch  25 -Loss: 12836.2578 Validation Accuracy: 0.261719\n",
      "Epoch  1, Batch  26 -Loss: 14679.6523 Validation Accuracy: 0.265625\n",
      "Epoch  1, Batch  27 -Loss: 13691.3838 Validation Accuracy: 0.261719\n",
      "Epoch  1, Batch  28 -Loss: 11995.3174 Validation Accuracy: 0.285156\n",
      "Epoch  1, Batch  29 -Loss: 12321.2832 Validation Accuracy: 0.273438\n",
      "Epoch  1, Batch  30 -Loss:  9775.9824 Validation Accuracy: 0.312500\n",
      "Epoch  1, Batch  31 -Loss: 12242.9844 Validation Accuracy: 0.296875\n",
      "Epoch  1, Batch  32 -Loss: 10779.1934 Validation Accuracy: 0.285156\n",
      "Epoch  1, Batch  33 -Loss: 10998.3086 Validation Accuracy: 0.300781\n",
      "Epoch  1, Batch  34 -Loss: 10148.3877 Validation Accuracy: 0.300781\n",
      "Epoch  1, Batch  35 -Loss: 13647.4434 Validation Accuracy: 0.296875\n",
      "Epoch  1, Batch  36 -Loss: 12018.0938 Validation Accuracy: 0.300781\n",
      "Epoch  1, Batch  37 -Loss:  9081.1562 Validation Accuracy: 0.304688\n",
      "Epoch  1, Batch  38 -Loss: 10118.1758 Validation Accuracy: 0.296875\n",
      "Epoch  1, Batch  39 -Loss: 10468.8740 Validation Accuracy: 0.312500\n",
      "Epoch  1, Batch  40 -Loss: 11158.3242 Validation Accuracy: 0.308594\n",
      "Epoch  1, Batch  41 -Loss: 10327.5293 Validation Accuracy: 0.351562\n",
      "Epoch  1, Batch  42 -Loss:  7574.4360 Validation Accuracy: 0.378906\n",
      "Epoch  1, Batch  43 -Loss:  8110.9209 Validation Accuracy: 0.375000\n",
      "Epoch  1, Batch  44 -Loss: 10922.9043 Validation Accuracy: 0.378906\n",
      "Epoch  1, Batch  45 -Loss: 10780.2969 Validation Accuracy: 0.367188\n",
      "Epoch  1, Batch  46 -Loss:  8916.7012 Validation Accuracy: 0.359375\n",
      "Epoch  1, Batch  47 -Loss:  8129.3291 Validation Accuracy: 0.359375\n",
      "Epoch  1, Batch  48 -Loss:  7674.8530 Validation Accuracy: 0.367188\n",
      "Epoch  1, Batch  49 -Loss:  9996.8555 Validation Accuracy: 0.371094\n",
      "Epoch  1, Batch  50 -Loss:  8034.6968 Validation Accuracy: 0.386719\n",
      "Epoch  1, Batch  51 -Loss:  8448.0410 Validation Accuracy: 0.386719\n",
      "Epoch  1, Batch  52 -Loss:  7268.1924 Validation Accuracy: 0.386719\n",
      "Epoch  1, Batch  53 -Loss:  8334.2217 Validation Accuracy: 0.390625\n",
      "Epoch  1, Batch  54 -Loss:  7919.9648 Validation Accuracy: 0.394531\n",
      "Epoch  1, Batch  55 -Loss:  6739.5142 Validation Accuracy: 0.402344\n",
      "Epoch  1, Batch  56 -Loss:  6991.0854 Validation Accuracy: 0.410156\n",
      "Epoch  1, Batch  57 -Loss:  7243.3213 Validation Accuracy: 0.414062\n",
      "Epoch  1, Batch  58 -Loss:  8621.2637 Validation Accuracy: 0.406250\n",
      "Epoch  1, Batch  59 -Loss:  7393.0967 Validation Accuracy: 0.410156\n",
      "Epoch  1, Batch  60 -Loss:  6827.8013 Validation Accuracy: 0.414062\n",
      "Epoch  1, Batch  61 -Loss:  6868.6963 Validation Accuracy: 0.398438\n",
      "Epoch  1, Batch  62 -Loss:  6773.4102 Validation Accuracy: 0.414062\n",
      "Epoch  1, Batch  63 -Loss:  5897.5889 Validation Accuracy: 0.433594\n",
      "Epoch  1, Batch  64 -Loss:  4963.8862 Validation Accuracy: 0.445312\n",
      "Epoch  1, Batch  65 -Loss:  6000.6504 Validation Accuracy: 0.437500\n",
      "Epoch  1, Batch  66 -Loss:  7623.3496 Validation Accuracy: 0.441406\n",
      "Epoch  1, Batch  67 -Loss:  7288.3745 Validation Accuracy: 0.449219\n",
      "Epoch  1, Batch  68 -Loss:  5627.6489 Validation Accuracy: 0.460938\n",
      "Epoch  1, Batch  69 -Loss:  7491.4082 Validation Accuracy: 0.457031\n",
      "Epoch  1, Batch  70 -Loss:  6042.0146 Validation Accuracy: 0.433594\n",
      "Epoch  1, Batch  71 -Loss:  6759.3867 Validation Accuracy: 0.445312\n",
      "Epoch  1, Batch  72 -Loss:  4806.7266 Validation Accuracy: 0.449219\n",
      "Epoch  1, Batch  73 -Loss:  6872.1279 Validation Accuracy: 0.472656\n",
      "Epoch  1, Batch  74 -Loss:  7061.5850 Validation Accuracy: 0.468750\n",
      "Epoch  1, Batch  75 -Loss:  4956.1426 Validation Accuracy: 0.480469\n",
      "Epoch  1, Batch  76 -Loss:  6235.2417 Validation Accuracy: 0.476562\n",
      "Epoch  1, Batch  77 -Loss:  7530.0400 Validation Accuracy: 0.488281\n",
      "Epoch  1, Batch  78 -Loss:  6508.6348 Validation Accuracy: 0.484375\n",
      "Epoch  1, Batch  79 -Loss:  5647.3115 Validation Accuracy: 0.488281\n",
      "Epoch  1, Batch  80 -Loss:  6449.7334 Validation Accuracy: 0.480469\n",
      "Epoch  1, Batch  81 -Loss:  4865.9521 Validation Accuracy: 0.496094\n",
      "Epoch  1, Batch  82 -Loss:  7668.8853 Validation Accuracy: 0.492188\n",
      "Epoch  1, Batch  83 -Loss:  6586.5337 Validation Accuracy: 0.484375\n",
      "Epoch  1, Batch  84 -Loss:  6321.5933 Validation Accuracy: 0.480469\n",
      "Epoch  1, Batch  85 -Loss:  5087.8589 Validation Accuracy: 0.476562\n",
      "Epoch  1, Batch  86 -Loss:  4466.2520 Validation Accuracy: 0.480469\n",
      "Epoch  1, Batch  87 -Loss:  6100.4824 Validation Accuracy: 0.507812\n",
      "Epoch  1, Batch  88 -Loss:  5842.4727 Validation Accuracy: 0.523438\n",
      "Epoch  1, Batch  89 -Loss:  4639.7939 Validation Accuracy: 0.511719\n",
      "Epoch  1, Batch  90 -Loss:  4573.6279 Validation Accuracy: 0.527344\n",
      "Epoch  1, Batch  91 -Loss:  6329.2266 Validation Accuracy: 0.519531\n",
      "Epoch  1, Batch  92 -Loss:  5084.4639 Validation Accuracy: 0.535156\n",
      "Epoch  1, Batch  93 -Loss:  5569.1670 Validation Accuracy: 0.539062\n",
      "Epoch  1, Batch  94 -Loss:  4995.1963 Validation Accuracy: 0.542969\n",
      "Epoch  1, Batch  95 -Loss:  5261.6699 Validation Accuracy: 0.542969\n",
      "Epoch  1, Batch  96 -Loss:  5735.4849 Validation Accuracy: 0.542969\n",
      "Epoch  1, Batch  97 -Loss:  3368.6763 Validation Accuracy: 0.539062\n",
      "Epoch  1, Batch  98 -Loss:  5895.2842 Validation Accuracy: 0.546875\n",
      "Epoch  1, Batch  99 -Loss:  4343.1123 Validation Accuracy: 0.539062\n",
      "Epoch  1, Batch 100 -Loss:  5318.8018 Validation Accuracy: 0.546875\n",
      "Epoch  1, Batch 101 -Loss:  5368.8716 Validation Accuracy: 0.550781\n",
      "Epoch  1, Batch 102 -Loss:  6004.0332 Validation Accuracy: 0.550781\n",
      "Epoch  1, Batch 103 -Loss:  5964.2651 Validation Accuracy: 0.542969\n",
      "Epoch  1, Batch 104 -Loss:  5072.2603 Validation Accuracy: 0.546875\n",
      "Epoch  1, Batch 105 -Loss:  4147.1831 Validation Accuracy: 0.550781\n",
      "Epoch  1, Batch 106 -Loss:  4948.9932 Validation Accuracy: 0.550781\n",
      "Epoch  1, Batch 107 -Loss:  4733.7998 Validation Accuracy: 0.550781\n",
      "Epoch  1, Batch 108 -Loss:  5025.9893 Validation Accuracy: 0.554688\n",
      "Epoch  1, Batch 109 -Loss:  3506.7429 Validation Accuracy: 0.558594\n",
      "Epoch  1, Batch 110 -Loss:  5784.3867 Validation Accuracy: 0.558594\n",
      "Epoch  1, Batch 111 -Loss:  4870.2119 Validation Accuracy: 0.566406\n",
      "Epoch  1, Batch 112 -Loss:  4838.1802 Validation Accuracy: 0.574219\n",
      "Epoch  1, Batch 113 -Loss:  4311.0645 Validation Accuracy: 0.570312\n",
      "Epoch  1, Batch 114 -Loss:  4100.9072 Validation Accuracy: 0.582031\n",
      "Epoch  1, Batch 115 -Loss:  4324.7402 Validation Accuracy: 0.582031\n",
      "Epoch  1, Batch 116 -Loss:  5207.6797 Validation Accuracy: 0.578125\n",
      "Epoch  1, Batch 117 -Loss:  4394.6104 Validation Accuracy: 0.566406\n",
      "Epoch  1, Batch 118 -Loss:  4729.6348 Validation Accuracy: 0.562500\n",
      "Epoch  1, Batch 119 -Loss:  3620.9534 Validation Accuracy: 0.570312\n",
      "Epoch  1, Batch 120 -Loss:  4376.7852 Validation Accuracy: 0.566406\n",
      "Epoch  1, Batch 121 -Loss:  5387.4165 Validation Accuracy: 0.570312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1, Batch 122 -Loss:  3061.9043 Validation Accuracy: 0.585938\n",
      "Epoch  1, Batch 123 -Loss:  3874.6116 Validation Accuracy: 0.578125\n",
      "Epoch  1, Batch 124 -Loss:  3877.4192 Validation Accuracy: 0.585938\n",
      "Epoch  1, Batch 125 -Loss:  4531.2593 Validation Accuracy: 0.593750\n",
      "Epoch  1, Batch 126 -Loss:  3788.4919 Validation Accuracy: 0.582031\n",
      "Epoch  1, Batch 127 -Loss:  3957.9973 Validation Accuracy: 0.582031\n",
      "Epoch  1, Batch 128 -Loss:  4440.9609 Validation Accuracy: 0.585938\n",
      "Epoch  1, Batch 129 -Loss:  4033.1343 Validation Accuracy: 0.574219\n",
      "Epoch  1, Batch 130 -Loss:  3954.9546 Validation Accuracy: 0.582031\n",
      "Epoch  1, Batch 131 -Loss:  4556.3569 Validation Accuracy: 0.593750\n",
      "Epoch  1, Batch 132 -Loss:  4635.2275 Validation Accuracy: 0.578125\n",
      "Epoch  1, Batch 133 -Loss:  4002.6279 Validation Accuracy: 0.578125\n",
      "Epoch  1, Batch 134 -Loss:  4937.0239 Validation Accuracy: 0.589844\n",
      "Epoch  1, Batch 135 -Loss:  4474.0571 Validation Accuracy: 0.593750\n",
      "Epoch  1, Batch 136 -Loss:  4677.2852 Validation Accuracy: 0.589844\n",
      "Epoch  1, Batch 137 -Loss:  3689.3572 Validation Accuracy: 0.605469\n",
      "Epoch  1, Batch 138 -Loss:  4253.2676 Validation Accuracy: 0.605469\n",
      "Epoch  1, Batch 139 -Loss:  5244.5137 Validation Accuracy: 0.601562\n",
      "Epoch  1, Batch 140 -Loss:  3385.5044 Validation Accuracy: 0.613281\n",
      "Epoch  1, Batch 141 -Loss:  3251.3579 Validation Accuracy: 0.601562\n",
      "Epoch  1, Batch 142 -Loss:  3817.6091 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 143 -Loss:  4806.3633 Validation Accuracy: 0.605469\n",
      "Epoch  1, Batch 144 -Loss:  3123.4661 Validation Accuracy: 0.601562\n",
      "Epoch  1, Batch 145 -Loss:  4652.7979 Validation Accuracy: 0.609375\n",
      "Epoch  1, Batch 146 -Loss:  4341.0566 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 147 -Loss:  4384.7061 Validation Accuracy: 0.621094\n",
      "Epoch  1, Batch 148 -Loss:  3814.5796 Validation Accuracy: 0.605469\n",
      "Epoch  1, Batch 149 -Loss:  3115.9058 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 150 -Loss:  2012.3019 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 151 -Loss:  3302.7520 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 152 -Loss:  2840.3428 Validation Accuracy: 0.625000\n",
      "Epoch  1, Batch 153 -Loss:  2955.4009 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 154 -Loss:  3492.9026 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 155 -Loss:  3678.7507 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 156 -Loss:  3193.1255 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 157 -Loss:  3325.0100 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 158 -Loss:  3978.7935 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 159 -Loss:  3878.5503 Validation Accuracy: 0.617188\n",
      "Epoch  1, Batch 160 -Loss:  3882.1616 Validation Accuracy: 0.625000\n",
      "Epoch  1, Batch 161 -Loss:  4348.6094 Validation Accuracy: 0.625000\n",
      "Epoch  1, Batch 162 -Loss:  4096.4507 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 163 -Loss:  3126.1450 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 164 -Loss:  3095.0374 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 165 -Loss:  4060.6301 Validation Accuracy: 0.636719\n",
      "Epoch  1, Batch 166 -Loss:  5039.5474 Validation Accuracy: 0.625000\n",
      "Epoch  1, Batch 167 -Loss:  3591.7261 Validation Accuracy: 0.632812\n",
      "Epoch  1, Batch 168 -Loss:  3272.6431 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 169 -Loss:  3307.9351 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 170 -Loss:  2799.9380 Validation Accuracy: 0.621094\n",
      "Epoch  1, Batch 171 -Loss:  2358.8489 Validation Accuracy: 0.621094\n",
      "Epoch  1, Batch 172 -Loss:  2910.9570 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 173 -Loss:  3158.7202 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 174 -Loss:  4003.2905 Validation Accuracy: 0.628906\n",
      "Epoch  1, Batch 175 -Loss:  2602.8652 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 176 -Loss:  3354.4873 Validation Accuracy: 0.640625\n",
      "Epoch  1, Batch 177 -Loss:  2235.8667 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch 178 -Loss:  3213.7817 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch 179 -Loss:  3460.6250 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch 180 -Loss:  2606.3525 Validation Accuracy: 0.648438\n",
      "Epoch  1, Batch 181 -Loss:  3095.5127 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch 182 -Loss:  3123.1445 Validation Accuracy: 0.648438\n",
      "Epoch  1, Batch 183 -Loss:  2764.1545 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch 184 -Loss:  3706.8525 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 185 -Loss:  3336.1768 Validation Accuracy: 0.644531\n",
      "Epoch  1, Batch 186 -Loss:  2131.9590 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 187 -Loss:  2154.8188 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 188 -Loss:  2994.5386 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 189 -Loss:  2192.4749 Validation Accuracy: 0.652344\n",
      "Epoch  1, Batch 190 -Loss:  3351.1777 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 191 -Loss:  3021.3113 Validation Accuracy: 0.667969\n",
      "Epoch  1, Batch 192 -Loss:  2359.0232 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 193 -Loss:  3169.9419 Validation Accuracy: 0.656250\n",
      "Epoch  1, Batch 194 -Loss:  1967.6917 Validation Accuracy: 0.664062\n",
      "Epoch  1, Batch 195 -Loss:  2971.7852 Validation Accuracy: 0.664062\n",
      "Epoch  1, Batch 196 -Loss:  2680.0669 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 197 -Loss:  3426.5137 Validation Accuracy: 0.667969\n",
      "Epoch  1, Batch 198 -Loss:  2773.3879 Validation Accuracy: 0.667969\n",
      "Epoch  1, Batch 199 -Loss:  2395.0676 Validation Accuracy: 0.660156\n",
      "Epoch  1, Batch 200 -Loss:  2757.9211 Validation Accuracy: 0.667969\n",
      "Epoch  1, Batch 201 -Loss:  4063.1926 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 202 -Loss:  2715.2842 Validation Accuracy: 0.675781\n",
      "Epoch  1, Batch 203 -Loss:  3249.7822 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 204 -Loss:  2180.3845 Validation Accuracy: 0.675781\n",
      "Epoch  1, Batch 205 -Loss:  3310.9482 Validation Accuracy: 0.675781\n",
      "Epoch  1, Batch 206 -Loss:  3341.4883 Validation Accuracy: 0.675781\n",
      "Epoch  1, Batch 207 -Loss:  2850.9641 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 208 -Loss:  3145.2083 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 209 -Loss:  2874.3904 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 210 -Loss:  2891.5264 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 211 -Loss:  2508.7168 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 212 -Loss:  2701.6013 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 213 -Loss:  2729.8547 Validation Accuracy: 0.675781\n",
      "Epoch  1, Batch 214 -Loss:  2972.3384 Validation Accuracy: 0.675781\n",
      "Epoch  1, Batch 215 -Loss:  2741.0425 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 216 -Loss:  3316.4248 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 217 -Loss:  2106.0137 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 218 -Loss:  2754.5820 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 219 -Loss:  2036.5728 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 220 -Loss:  2773.8945 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 221 -Loss:  2825.2822 Validation Accuracy: 0.675781\n",
      "Epoch  1, Batch 222 -Loss:  2600.4297 Validation Accuracy: 0.667969\n",
      "Epoch  1, Batch 223 -Loss:  3345.2275 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 224 -Loss:  2920.9878 Validation Accuracy: 0.675781\n",
      "Epoch  1, Batch 225 -Loss:  2002.6777 Validation Accuracy: 0.675781\n",
      "Epoch  1, Batch 226 -Loss:  2931.3940 Validation Accuracy: 0.667969\n",
      "Epoch  1, Batch 227 -Loss:  3561.4697 Validation Accuracy: 0.675781\n",
      "Epoch  1, Batch 228 -Loss:  2475.2805 Validation Accuracy: 0.675781\n",
      "Epoch  1, Batch 229 -Loss:  2772.1919 Validation Accuracy: 0.675781\n",
      "Epoch  1, Batch 230 -Loss:  2494.3740 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 231 -Loss:  2060.9595 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 232 -Loss:  2931.9587 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 233 -Loss:  2629.0562 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 234 -Loss:  1883.8584 Validation Accuracy: 0.675781\n",
      "Epoch  1, Batch 235 -Loss:  2150.2764 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 236 -Loss:  2386.7861 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 237 -Loss:  1696.5609 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 238 -Loss:  2193.3843 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 239 -Loss:  2258.5361 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 240 -Loss:  2772.9546 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 241 -Loss:  2752.1392 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 242 -Loss:  1689.7974 Validation Accuracy: 0.679688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1, Batch 243 -Loss:  2088.2544 Validation Accuracy: 0.675781\n",
      "Epoch  1, Batch 244 -Loss:  2265.4707 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 245 -Loss:  1919.8220 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 246 -Loss:  2486.0122 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 247 -Loss:  1924.4921 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 248 -Loss:  2712.5146 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 249 -Loss:  2096.2646 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 250 -Loss:  1900.2557 Validation Accuracy: 0.667969\n",
      "Epoch  1, Batch 251 -Loss:  2170.8533 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 252 -Loss:  2986.0630 Validation Accuracy: 0.675781\n",
      "Epoch  1, Batch 253 -Loss:  1743.3022 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 254 -Loss:  2231.2539 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 255 -Loss:  2431.8857 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 256 -Loss:  1781.2157 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 257 -Loss:  1521.8416 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 258 -Loss:  3054.6169 Validation Accuracy: 0.683594\n",
      "Epoch  1, Batch 259 -Loss:  2844.2698 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 260 -Loss:  1568.6193 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 261 -Loss:  2544.8462 Validation Accuracy: 0.671875\n",
      "Epoch  1, Batch 262 -Loss:  1532.1279 Validation Accuracy: 0.667969\n",
      "Epoch  1, Batch 263 -Loss:  2357.7561 Validation Accuracy: 0.667969\n",
      "Epoch  1, Batch 264 -Loss:  2375.8755 Validation Accuracy: 0.675781\n",
      "Epoch  1, Batch 265 -Loss:  3062.2620 Validation Accuracy: 0.679688\n",
      "Epoch  1, Batch 266 -Loss:  2060.3613 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 267 -Loss:  2325.2004 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 268 -Loss:  2633.3799 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 269 -Loss:  2324.7158 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 270 -Loss:  2469.9836 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 271 -Loss:  2441.4141 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 272 -Loss:  2250.6238 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 273 -Loss:  1920.2571 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 274 -Loss:  1461.5991 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 275 -Loss:  1973.0786 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 276 -Loss:  2283.4385 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 277 -Loss:  1907.6895 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 278 -Loss:  2492.0383 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 279 -Loss:  2502.1240 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 280 -Loss:  2078.5076 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 281 -Loss:  1990.3301 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 282 -Loss:  2061.6052 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 283 -Loss:  1939.7069 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 284 -Loss:  2679.9385 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 285 -Loss:  2147.7969 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 286 -Loss:  2001.3259 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 287 -Loss:  1926.1646 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 288 -Loss:  2483.8350 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 289 -Loss:  2826.5283 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 290 -Loss:  1266.2891 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 291 -Loss:  2394.7329 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 292 -Loss:  2051.2368 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 293 -Loss:  1760.6772 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 294 -Loss:   764.2208 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 295 -Loss:  3033.9424 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 296 -Loss:  2561.6624 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 297 -Loss:  1249.0872 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 298 -Loss:  2113.9253 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 299 -Loss:  2169.6956 Validation Accuracy: 0.687500\n",
      "Epoch  1, Batch 300 -Loss:  2047.7163 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 301 -Loss:  2282.0979 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 302 -Loss:  2104.4778 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 303 -Loss:  2691.0464 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 304 -Loss:  2325.9219 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 305 -Loss:  2087.3911 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 306 -Loss:  1430.0911 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 307 -Loss:  2716.3076 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 308 -Loss:  1814.5879 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 309 -Loss:  1124.3240 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 310 -Loss:  2184.4509 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 311 -Loss:  1804.1880 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 312 -Loss:  1516.1938 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 313 -Loss:  2071.1699 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 314 -Loss:  1534.0605 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 315 -Loss:  1745.6028 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 316 -Loss:  1968.8580 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 317 -Loss:  1575.6449 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 318 -Loss:  1808.7412 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 319 -Loss:  1888.6484 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 320 -Loss:  1725.5840 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 321 -Loss:  2051.7080 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 322 -Loss:  1556.5438 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 323 -Loss:  1687.5837 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 324 -Loss:  2300.6316 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 325 -Loss:  2023.8469 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 326 -Loss:  1324.9426 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 327 -Loss:  1646.1914 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 328 -Loss:  2199.0840 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 329 -Loss:  1490.3671 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 330 -Loss:  2345.3254 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 331 -Loss:  2112.2280 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 332 -Loss:  2273.1714 Validation Accuracy: 0.699219\n",
      "Epoch  1, Batch 333 -Loss:  2068.9851 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 334 -Loss:  1762.9006 Validation Accuracy: 0.691406\n",
      "Epoch  1, Batch 335 -Loss:  1838.8103 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 336 -Loss:  1948.7383 Validation Accuracy: 0.695312\n",
      "Epoch  1, Batch 337 -Loss:  1921.7371 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 338 -Loss:  2417.9023 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 339 -Loss:  2020.7654 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 340 -Loss:  1436.5154 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 341 -Loss:  1701.1670 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 342 -Loss:  1495.5676 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 343 -Loss:  1819.5269 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 344 -Loss:  1494.4301 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 345 -Loss:  2296.5168 Validation Accuracy: 0.710938\n",
      "Epoch  1, Batch 346 -Loss:  1554.8003 Validation Accuracy: 0.707031\n",
      "Epoch  1, Batch 347 -Loss:  1800.9104 Validation Accuracy: 0.703125\n",
      "Epoch  1, Batch 348 -Loss:  1561.7957 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 349 -Loss:  1286.5715 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 350 -Loss:  1410.7771 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 351 -Loss:  1898.8965 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 352 -Loss:  2117.6523 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 353 -Loss:  1414.7236 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 354 -Loss:  1765.2161 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 355 -Loss:  2119.2273 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 356 -Loss:  1686.2554 Validation Accuracy: 0.738281\n",
      "Epoch  1, Batch 357 -Loss:  2258.4241 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 358 -Loss:  1894.1472 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 359 -Loss:  1334.1395 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 360 -Loss:  1281.8204 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 361 -Loss:  1408.4421 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 362 -Loss:  1461.3896 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 363 -Loss:  1414.1842 Validation Accuracy: 0.726562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1, Batch 364 -Loss:  1673.0547 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 365 -Loss:  1542.4385 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 366 -Loss:  1468.5836 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 367 -Loss:  1790.9500 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 368 -Loss:  2004.1906 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 369 -Loss:  1616.0000 Validation Accuracy: 0.714844\n",
      "Epoch  1, Batch 370 -Loss:  2066.8003 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 371 -Loss:  2003.6161 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 372 -Loss:  1415.4486 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 373 -Loss:  2527.1372 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 374 -Loss:  1625.4677 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 375 -Loss:  1591.6479 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 376 -Loss:  1398.5269 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 377 -Loss:  1925.5479 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 378 -Loss:  1417.5288 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 379 -Loss:  1448.5127 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 380 -Loss:  2364.2593 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 381 -Loss:  1894.8943 Validation Accuracy: 0.742188\n",
      "Epoch  1, Batch 382 -Loss:  1445.7896 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 383 -Loss:  1556.8550 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 384 -Loss:  1461.8676 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 385 -Loss:  1819.8525 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 386 -Loss:  1252.6420 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 387 -Loss:  2206.2388 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 388 -Loss:  1711.2483 Validation Accuracy: 0.722656\n",
      "Epoch  1, Batch 389 -Loss:  1968.6177 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 390 -Loss:  1744.9342 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 391 -Loss:  1540.3933 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 392 -Loss:  1735.4775 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 393 -Loss:  1117.7620 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 394 -Loss:  1977.6101 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 395 -Loss:  1267.0205 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 396 -Loss:  1399.8556 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 397 -Loss:  1769.6880 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 398 -Loss:  1912.2960 Validation Accuracy: 0.742188\n",
      "Epoch  1, Batch 399 -Loss:  1185.2302 Validation Accuracy: 0.738281\n",
      "Epoch  1, Batch 400 -Loss:  1764.0310 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 401 -Loss:  1548.0476 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 402 -Loss:  1587.4146 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 403 -Loss:  1499.1111 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 404 -Loss:  1487.9213 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 405 -Loss:  1175.9181 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 406 -Loss:  1699.6603 Validation Accuracy: 0.746094\n",
      "Epoch  1, Batch 407 -Loss:  1773.3804 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 408 -Loss:  1619.7310 Validation Accuracy: 0.730469\n",
      "Epoch  1, Batch 409 -Loss:  1695.3833 Validation Accuracy: 0.726562\n",
      "Epoch  1, Batch 410 -Loss:  1394.4266 Validation Accuracy: 0.718750\n",
      "Epoch  1, Batch 411 -Loss:  1284.2239 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 412 -Loss:  2262.6768 Validation Accuracy: 0.738281\n",
      "Epoch  1, Batch 413 -Loss:  1874.3435 Validation Accuracy: 0.734375\n",
      "Epoch  1, Batch 414 -Loss:  1339.4795 Validation Accuracy: 0.742188\n",
      "Epoch  1, Batch 415 -Loss:  1177.2831 Validation Accuracy: 0.746094\n",
      "Epoch  1, Batch 416 -Loss:  2399.0254 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 417 -Loss:  1568.4443 Validation Accuracy: 0.750000\n",
      "Epoch  1, Batch 418 -Loss:  2049.0977 Validation Accuracy: 0.757812\n",
      "Epoch  1, Batch 419 -Loss:  1925.8579 Validation Accuracy: 0.757812\n",
      "Epoch  1, Batch 420 -Loss:  1501.7434 Validation Accuracy: 0.753906\n",
      "Epoch  1, Batch 421 -Loss:   918.5804 Validation Accuracy: 0.757812\n",
      "Epoch  1, Batch 422 -Loss:  1738.5225 Validation Accuracy: 0.750000\n",
      "Epoch  1, Batch 423 -Loss:  1410.2834 Validation Accuracy: 0.757812\n",
      "Epoch  1, Batch 424 -Loss:  1217.9448 Validation Accuracy: 0.757812\n",
      "Epoch  1, Batch 425 -Loss:  1720.5104 Validation Accuracy: 0.750000\n",
      "Epoch  1, Batch 426 -Loss:  1147.3608 Validation Accuracy: 0.750000\n",
      "Epoch  1, Batch 427 -Loss:  1060.7513 Validation Accuracy: 0.757812\n",
      "Epoch  1, Batch 428 -Loss:  1291.1848 Validation Accuracy: 0.746094\n",
      "Epoch  1, Batch 429 -Loss:  1795.2715 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch   1 -Loss:  1175.1382 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch   2 -Loss:  1338.3660 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch   3 -Loss:  1323.6006 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch   4 -Loss:  1833.5156 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch   5 -Loss:  1709.4122 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch   6 -Loss:  2355.4744 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch   7 -Loss:  1609.6586 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch   8 -Loss:  1686.1104 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch   9 -Loss:   969.4105 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch  10 -Loss:  1991.1976 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch  11 -Loss:  1186.1589 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch  12 -Loss:  1888.0117 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch  13 -Loss:  1353.7434 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch  14 -Loss:  1587.2446 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch  15 -Loss:  2424.1057 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch  16 -Loss:  1683.7698 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch  17 -Loss:  1474.4030 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch  18 -Loss:  2310.7922 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch  19 -Loss:  1786.9055 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch  20 -Loss:  1963.6104 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch  21 -Loss:  1310.6776 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch  22 -Loss:  1703.7618 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch  23 -Loss:  1272.9824 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch  24 -Loss:  1484.8540 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch  25 -Loss:  1222.9395 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch  26 -Loss:  1340.8105 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch  27 -Loss:  1786.8420 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch  28 -Loss:  1826.6985 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch  29 -Loss:  1287.4568 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch  30 -Loss:  1271.9904 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch  31 -Loss:  1735.8145 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch  32 -Loss:  1651.9204 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch  33 -Loss:  1244.0200 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch  34 -Loss:  1018.9747 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch  35 -Loss:  1999.2306 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch  36 -Loss:  1333.6255 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch  37 -Loss:  1759.3236 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch  38 -Loss:  1093.9465 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch  39 -Loss:  1012.2514 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch  40 -Loss:  1404.3782 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch  41 -Loss:  1275.6628 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch  42 -Loss:  1497.6013 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch  43 -Loss:  1011.0189 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch  44 -Loss:  1095.3817 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch  45 -Loss:  1056.1886 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch  46 -Loss:  1429.4087 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch  47 -Loss:  1539.2935 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch  48 -Loss:  1747.4321 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch  49 -Loss:  1452.4949 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch  50 -Loss:  1345.3875 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch  51 -Loss:  1307.4802 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch  52 -Loss:  1420.8987 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch  53 -Loss:   493.9150 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch  54 -Loss:  1234.6238 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch  55 -Loss:  1279.3472 Validation Accuracy: 0.765625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2, Batch  56 -Loss:  1810.1443 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch  57 -Loss:  1410.3936 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch  58 -Loss:  1463.2666 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch  59 -Loss:  1165.7468 Validation Accuracy: 0.738281\n",
      "Epoch  2, Batch  60 -Loss:  1473.4794 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch  61 -Loss:  1624.3733 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch  62 -Loss:  1534.0933 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch  63 -Loss:  1555.5657 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch  64 -Loss:  1280.4519 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch  65 -Loss:   794.4780 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch  66 -Loss:  1175.9705 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch  67 -Loss:  1196.2223 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch  68 -Loss:   820.0160 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch  69 -Loss:  1529.3254 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch  70 -Loss:  1371.2153 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch  71 -Loss:  1259.2144 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch  72 -Loss:   944.0255 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch  73 -Loss:  1145.3755 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch  74 -Loss:  1594.0203 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch  75 -Loss:  1268.8911 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch  76 -Loss:  1204.3247 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch  77 -Loss:   790.5697 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch  78 -Loss:  1387.7661 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch  79 -Loss:  1236.4768 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch  80 -Loss:   906.8752 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch  81 -Loss:  1539.0483 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch  82 -Loss:  1656.8790 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch  83 -Loss:  1428.5754 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch  84 -Loss:  1589.1655 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch  85 -Loss:  1208.0963 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch  86 -Loss:  1191.4031 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch  87 -Loss:  1182.2468 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch  88 -Loss:  1171.1359 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch  89 -Loss:  1565.6877 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch  90 -Loss:  1154.8738 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch  91 -Loss:  1544.4451 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch  92 -Loss:  1181.6292 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch  93 -Loss:  1104.6881 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch  94 -Loss:  1330.4969 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch  95 -Loss:  1315.0500 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch  96 -Loss:  1068.5868 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch  97 -Loss:  1190.0625 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch  98 -Loss:  1433.9574 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch  99 -Loss:  1273.1914 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 100 -Loss:  1281.4355 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 101 -Loss:  1209.7979 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 102 -Loss:  1326.2668 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 103 -Loss:  1278.8833 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 104 -Loss:  1083.9066 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 105 -Loss:  1664.1517 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 106 -Loss:  1397.5713 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 107 -Loss:  1004.2982 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 108 -Loss:  1554.5479 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 109 -Loss:  1394.9706 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 110 -Loss:  1192.3085 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 111 -Loss:  1119.3706 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 112 -Loss:  1546.3455 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 113 -Loss:   732.8529 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 114 -Loss:  1247.9307 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 115 -Loss:   835.1367 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 116 -Loss:  1090.9348 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 117 -Loss:   972.7650 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 118 -Loss:   901.1613 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 119 -Loss:  1538.0797 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 120 -Loss:  1330.7477 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 121 -Loss:   767.2164 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 122 -Loss:  1593.7344 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 123 -Loss:  1116.4280 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 124 -Loss:  1146.7793 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 125 -Loss:   850.5339 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 126 -Loss:  1067.8378 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 127 -Loss:   769.3245 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 128 -Loss:  1807.9503 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 129 -Loss:   916.3090 Validation Accuracy: 0.742188\n",
      "Epoch  2, Batch 130 -Loss:  1381.5852 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 131 -Loss:  1055.1284 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 132 -Loss:  1212.4543 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 133 -Loss:  1521.5490 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 134 -Loss:  1418.7078 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 135 -Loss:  1412.9279 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 136 -Loss:  1835.6371 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 137 -Loss:   774.3939 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 138 -Loss:  1062.4747 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 139 -Loss:  1205.9276 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 140 -Loss:   962.2076 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 141 -Loss:   969.7122 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 142 -Loss:  1244.6929 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 143 -Loss:  1361.1373 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 144 -Loss:  1233.8687 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 145 -Loss:  1677.1904 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 146 -Loss:  1186.7146 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 147 -Loss:  1681.0627 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 148 -Loss:   835.1071 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 149 -Loss:  1234.1096 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 150 -Loss:  1617.2881 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 151 -Loss:   993.8818 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 152 -Loss:  1232.2128 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 153 -Loss:   820.5275 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 154 -Loss:  1143.8158 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 155 -Loss:   927.5461 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 156 -Loss:   752.0195 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 157 -Loss:  1147.2974 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 158 -Loss:  1257.5449 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 159 -Loss:  1208.1881 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 160 -Loss:  1266.4985 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 161 -Loss:  1182.3605 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 162 -Loss:  1199.3533 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 163 -Loss:  1305.2791 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 164 -Loss:  1137.0416 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 165 -Loss:   902.0597 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 166 -Loss:   817.3868 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 167 -Loss:  1066.4204 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 168 -Loss:  1304.2104 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 169 -Loss:   858.4386 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 170 -Loss:  1212.7706 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 171 -Loss:  1100.0592 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 172 -Loss:  1605.6882 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 173 -Loss:  1417.2151 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 174 -Loss:   721.7292 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 175 -Loss:  1473.6350 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 176 -Loss:  1313.8110 Validation Accuracy: 0.753906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2, Batch 177 -Loss:   948.2451 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 178 -Loss:  1227.5469 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 179 -Loss:  1311.3496 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 180 -Loss:  1146.7322 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 181 -Loss:   864.1144 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 182 -Loss:  1246.3916 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 183 -Loss:  1495.9332 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 184 -Loss:   775.9400 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 185 -Loss:   982.3534 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 186 -Loss:  1125.0867 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 187 -Loss:  1679.8915 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 188 -Loss:  1185.3784 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 189 -Loss:  1727.3887 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 190 -Loss:  1258.6682 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 191 -Loss:  1206.9401 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 192 -Loss:   633.7219 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 193 -Loss:  1102.6637 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 194 -Loss:  1223.8708 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 195 -Loss:  1527.6028 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 196 -Loss:  1028.3911 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 197 -Loss:  1050.9355 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 198 -Loss:  1324.8521 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 199 -Loss:  1175.4688 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 200 -Loss:  1103.6179 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 201 -Loss:  1156.0011 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 202 -Loss:  1436.1393 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 203 -Loss:   755.0045 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 204 -Loss:  1382.9062 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 205 -Loss:  1155.2832 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 206 -Loss:   946.5956 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 207 -Loss:   944.7148 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 208 -Loss:  1148.8481 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 209 -Loss:   894.1906 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 210 -Loss:   757.0614 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 211 -Loss:  1034.0350 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 212 -Loss:   968.9832 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 213 -Loss:  1075.5452 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 214 -Loss:  1026.3145 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 215 -Loss:  1090.2975 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 216 -Loss:  1024.2295 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 217 -Loss:   905.8303 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 218 -Loss:   728.8171 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 219 -Loss:  1354.2465 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 220 -Loss:  1126.3682 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 221 -Loss:   938.2415 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 222 -Loss:  1064.0598 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 223 -Loss:  1752.3008 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 224 -Loss:  1104.2921 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 225 -Loss:  1492.8386 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 226 -Loss:  1084.9576 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 227 -Loss:  1402.5344 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 228 -Loss:  1159.6108 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 229 -Loss:  1239.6912 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 230 -Loss:  1094.0691 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 231 -Loss:   793.0048 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 232 -Loss:  1373.9044 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 233 -Loss:   566.6548 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 234 -Loss:  1140.8418 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 235 -Loss:   932.6298 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 236 -Loss:   948.9488 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 237 -Loss:  1074.0397 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 238 -Loss:   637.7338 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 239 -Loss:  1259.2159 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 240 -Loss:  1402.4021 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 241 -Loss:   887.1901 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 242 -Loss:   790.3845 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 243 -Loss:   996.4606 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 244 -Loss:  1279.0576 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 245 -Loss:  1213.9465 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 246 -Loss:  1102.6124 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 247 -Loss:  1135.1172 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 248 -Loss:   749.5910 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 249 -Loss:   931.5232 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 250 -Loss:  1136.1870 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 251 -Loss:   926.1976 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 252 -Loss:  1233.3931 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 253 -Loss:   831.9913 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 254 -Loss:  1173.7196 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 255 -Loss:   653.8924 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 256 -Loss:  1401.0206 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 257 -Loss:  1000.5872 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 258 -Loss:  1084.7764 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 259 -Loss:   916.2939 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 260 -Loss:  1040.2561 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 261 -Loss:  1352.3888 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 262 -Loss:  1025.4056 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 263 -Loss:  1158.7903 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 264 -Loss:   916.5424 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 265 -Loss:  1105.7473 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 266 -Loss:  1121.8158 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 267 -Loss:   973.6111 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 268 -Loss:   759.9875 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 269 -Loss:   898.4485 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 270 -Loss:  1146.5649 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 271 -Loss:  1270.3217 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 272 -Loss:  1259.3199 Validation Accuracy: 0.746094\n",
      "Epoch  2, Batch 273 -Loss:  1237.1890 Validation Accuracy: 0.750000\n",
      "Epoch  2, Batch 274 -Loss:  1192.9607 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 275 -Loss:   913.1206 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 276 -Loss:   523.3702 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 277 -Loss:   820.5004 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 278 -Loss:  1203.0947 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 279 -Loss:   878.5366 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 280 -Loss:  1233.1604 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 281 -Loss:  1409.1226 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 282 -Loss:  1174.0593 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 283 -Loss:  1189.7966 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 284 -Loss:   815.1362 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 285 -Loss:   573.0178 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 286 -Loss:  1237.1229 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 287 -Loss:  1193.2592 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 288 -Loss:   967.7532 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 289 -Loss:   686.4465 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 290 -Loss:  1497.0695 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 291 -Loss:  1257.6008 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 292 -Loss:  1327.5760 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 293 -Loss:  1032.5087 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 294 -Loss:  1218.4536 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 295 -Loss:  1223.6658 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 296 -Loss:   956.0798 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 297 -Loss:   719.5725 Validation Accuracy: 0.761719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2, Batch 298 -Loss:   941.2608 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 299 -Loss:  1045.6921 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 300 -Loss:  1148.6527 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 301 -Loss:   975.0853 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 302 -Loss:  1181.3484 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 303 -Loss:  1309.2761 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 304 -Loss:   779.1473 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 305 -Loss:   640.4700 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 306 -Loss:  1451.2163 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 307 -Loss:  1246.7462 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 308 -Loss:   889.4354 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 309 -Loss:   948.5020 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 310 -Loss:  1141.0087 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 311 -Loss:  1124.0542 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 312 -Loss:  1121.0149 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 313 -Loss:  1624.8981 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 314 -Loss:   976.4284 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 315 -Loss:   691.6981 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 316 -Loss:  1275.9646 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 317 -Loss:  1160.0073 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 318 -Loss:   712.3480 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 319 -Loss:   775.2183 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 320 -Loss:  1396.5608 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 321 -Loss:   865.9632 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 322 -Loss:   955.7535 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 323 -Loss:   697.8418 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 324 -Loss:   863.3170 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 325 -Loss:   739.6475 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 326 -Loss:   966.6462 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 327 -Loss:  1185.2759 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 328 -Loss:  1043.5288 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 329 -Loss:   827.8423 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 330 -Loss:   709.8440 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 331 -Loss:   834.0437 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 332 -Loss:   933.3428 Validation Accuracy: 0.753906\n",
      "Epoch  2, Batch 333 -Loss:  1217.7568 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 334 -Loss:  1342.5929 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 335 -Loss:   833.2682 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 336 -Loss:  1093.9368 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 337 -Loss:   953.8743 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 338 -Loss:  1023.5852 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 339 -Loss:   793.2124 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 340 -Loss:   891.7372 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 341 -Loss:   621.6417 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 342 -Loss:  1112.5881 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 343 -Loss:  1348.1841 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 344 -Loss:  1702.9845 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 345 -Loss:   716.7449 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 346 -Loss:  1188.9641 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 347 -Loss:  1263.2784 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 348 -Loss:  1177.4370 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 349 -Loss:   967.0181 Validation Accuracy: 0.757812\n",
      "Epoch  2, Batch 350 -Loss:   767.3741 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 351 -Loss:   871.4927 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 352 -Loss:   750.3813 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 353 -Loss:   809.0919 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 354 -Loss:   756.9954 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 355 -Loss:   386.3605 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 356 -Loss:  1241.8867 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 357 -Loss:   673.9851 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 358 -Loss:  1048.3796 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 359 -Loss:  1057.8489 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 360 -Loss:   683.7220 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 361 -Loss:   996.5974 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 362 -Loss:  1189.4482 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 363 -Loss:   521.7986 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 364 -Loss:  1182.2313 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch 365 -Loss:   808.8832 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 366 -Loss:   729.3975 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch 367 -Loss:   907.0942 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 368 -Loss:  1223.8513 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 369 -Loss:  1010.4488 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 370 -Loss:   972.9908 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 371 -Loss:   843.0535 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 372 -Loss:   841.5828 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 373 -Loss:   892.5433 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 374 -Loss:  1236.3633 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 375 -Loss:  1190.8191 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 376 -Loss:  1108.0278 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 377 -Loss:   900.4838 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 378 -Loss:   595.4049 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 379 -Loss:   902.3478 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 380 -Loss:   746.0967 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch 381 -Loss:  1032.2903 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 382 -Loss:   652.2927 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 383 -Loss:   616.1890 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 384 -Loss:  1071.6797 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 385 -Loss:   860.2694 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 386 -Loss:   738.8768 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 387 -Loss:  1084.9077 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 388 -Loss:   952.3848 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 389 -Loss:  1081.4420 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 390 -Loss:   806.7056 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 391 -Loss:   698.0012 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 392 -Loss:  1439.0686 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 393 -Loss:   877.1708 Validation Accuracy: 0.781250\n",
      "Epoch  2, Batch 394 -Loss:   978.8628 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 395 -Loss:   855.3563 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 396 -Loss:   845.2642 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 397 -Loss:   624.7538 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 398 -Loss:  1114.0916 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 399 -Loss:   743.0372 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 400 -Loss:   984.5184 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 401 -Loss:  1150.4318 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 402 -Loss:  1008.3658 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 403 -Loss:   719.8741 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 404 -Loss:   839.1770 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 405 -Loss:   755.3784 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 406 -Loss:  1159.8901 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 407 -Loss:  1226.4055 Validation Accuracy: 0.761719\n",
      "Epoch  2, Batch 408 -Loss:   768.0599 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 409 -Loss:   484.5604 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 410 -Loss:   769.0615 Validation Accuracy: 0.765625\n",
      "Epoch  2, Batch 411 -Loss:   876.6249 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 412 -Loss:   996.9681 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 413 -Loss:   984.2260 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 414 -Loss:   989.4261 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 415 -Loss:   765.0822 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 416 -Loss:  1207.4609 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 417 -Loss:   620.6183 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 418 -Loss:   981.0017 Validation Accuracy: 0.769531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2, Batch 419 -Loss:  1052.6155 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 420 -Loss:   608.9606 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 421 -Loss:   803.9376 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 422 -Loss:   559.1276 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 423 -Loss:   931.1456 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 424 -Loss:  1096.6008 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 425 -Loss:   615.0930 Validation Accuracy: 0.769531\n",
      "Epoch  2, Batch 426 -Loss:   789.5399 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 427 -Loss:   924.2156 Validation Accuracy: 0.777344\n",
      "Epoch  2, Batch 428 -Loss:   964.8839 Validation Accuracy: 0.773438\n",
      "Epoch  2, Batch 429 -Loss:  1322.6605 Validation Accuracy: 0.769531\n",
      "Testing Accuracy: 0.81640625\n"
     ]
    }
   ],
   "source": [
    "# tf Graph input\n",
    "x = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "y = tf.placeholder(tf.float32, [None, n_classes])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, weights, biases, keep_prob)\n",
    "\n",
    "# Define loss and optimizer\n",
    "cost = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for batch in range(mnist.train.num_examples//batch_size):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            sess.run(optimizer, feed_dict={\n",
    "                x: batch_x,\n",
    "                y: batch_y,\n",
    "                keep_prob: dropout})\n",
    "\n",
    "            # Calculate batch loss and accuracy\n",
    "            loss = sess.run(cost, feed_dict={\n",
    "                x: batch_x,\n",
    "                y: batch_y,\n",
    "                keep_prob: 1.})\n",
    "            valid_acc = sess.run(accuracy, feed_dict={\n",
    "                x: mnist.validation.images[:test_valid_size],\n",
    "                y: mnist.validation.labels[:test_valid_size],\n",
    "                keep_prob: 1.})\n",
    "\n",
    "            print('Epoch {:>2}, Batch {:>3} -'\n",
    "                  'Loss: {:>10.4f} Validation Accuracy: {:.6f}'.format(\n",
    "                epoch + 1,\n",
    "                batch + 1,\n",
    "                loss,\n",
    "                valid_acc))\n",
    "\n",
    "    # Calculate Test Accuracy\n",
    "    test_acc = sess.run(accuracy, feed_dict={\n",
    "        x: mnist.test.images[:test_valid_size],\n",
    "        y: mnist.test.labels[:test_valid_size],\n",
    "        keep_prob: 1.})\n",
    "    print('Testing Accuracy: {}'.format(test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 使用 TensorFlow 做卷积"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Setup the strides, padding and filter weight/bias such that\n",
    "the output shape is (1, 2, 2, 3).\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# `tf.nn.conv2d` requires the input be 4D (batch_size, height, width, depth)\n",
    "# (1, 4, 4, 1)\n",
    "x = np.array([\n",
    "    [0, 1, 0.5, 10],\n",
    "    [2, 2.5, 1, -8],\n",
    "    [4, 0, 5, 6],\n",
    "    [15, 1, 2, 3]], dtype=np.float32).reshape((1, 4, 4, 1))\n",
    "X = tf.constant(x)\n",
    "\n",
    "\n",
    "def conv2d(input):\n",
    "    # Filter (weights and bias)\n",
    "    # The shape of the filter weight is (height, width, input_depth, output_depth)\n",
    "    # The shape of the filter bias is (output_depth,)\n",
    "    # TODO: Define the filter weights `F_W` and filter bias `F_b`.\n",
    "    # NOTE: Remember to wrap them in `tf.Variable`, they are trainable parameters after all.\n",
    "    F_W = tf.Variable(tf.truncated_normal([2, 2, 1, 3]))\n",
    "    F_b = tf.Variable(tf.zeros(3))\n",
    "    # TODO: Set the stride for each dimension (batch_size, height, width, depth)\n",
    "    strides = [1, 2, 2, 1]\n",
    "    # TODO: set the padding, either 'VALID' or 'SAME'.\n",
    "    padding = 'SAME'\n",
    "    # https://www.tensorflow.org/versions/r0.11/api_docs/python/nn.html#conv2d\n",
    "    # `tf.nn.conv2d` does not include the bias computation so we have to add it ourselves after.\n",
    "    return tf.nn.conv2d(input, F_W, strides, padding) + F_b\n",
    "\n",
    "out = conv2d(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 在 TensorFlow 中使用池化层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Set the values to `strides` and `ksize` such that\n",
    "the output shape after pooling is (1, 2, 2, 1).\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# `tf.nn.max_pool` requires the input be 4D (batch_size, height, width, depth)\n",
    "# (1, 4, 4, 1)\n",
    "x = np.array([\n",
    "    [0, 1, 0.5, 10],\n",
    "    [2, 2.5, 1, -8],\n",
    "    [4, 0, 5, 6],\n",
    "    [15, 1, 2, 3]], dtype=np.float32).reshape((1, 4, 4, 1))\n",
    "X = tf.constant(x)\n",
    "\n",
    "def maxpool(input):\n",
    "    # TODO: Set the ksize (filter size) for each dimension (batch_size, height, width, depth)\n",
    "    ksize = [1, 2, 2, 1]\n",
    "    # TODO: Set the stride for each dimension (batch_size, height, width, depth)\n",
    "    strides = [1, 2, 2, 1]\n",
    "    # TODO: set the padding, either 'VALID' or 'SAME'.\n",
    "    padding = 'SAME'\n",
    "    # https://www.tensorflow.org/versions/r0.11/api_docs/python/nn.html#max_pool\n",
    "    return tf.nn.max_pool(input, ksize, strides, padding)\n",
    "    \n",
    "out = maxpool(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
